{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yopine Natural Content Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the natural content 'Categories' that have been created via app usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All content is presented in ‘Explore’ view today simply chronological.  Users shouldn’t have to sift through content that is of no interest to them.  Everything we need to know is contained in the questions and the responses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to let Machine Learning do that work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one table in the Yopine schema that contains all relevant data:  POLL\n",
    "https://www.dropbox.com/s/6l2o2mitruef5x7/PollTable.png?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the POLL table that contains all relevant data:  pollQuestion & pollAnswer\n",
    "https://www.dropbox.com/s/xwjin2qehkuoixu/PollTableCols.png?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data file\n",
    "https://www.dropbox.com/s/iql221nnoyk8ntf/poll3.csv?dl=0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample pollQuestion:  \n",
    "\n",
    "'Fitness: What's your jam?' (row 4241)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample pollAnswer:  \n",
    "\n",
    "[ { \"ansId\" : 1424014758471, \"answerText\" : \"Weights\", \"createdAt\" : { \"$date\" : 1424014758471 }, \"name\" : \"Yopine\", \"orderNumber\" : 1, \"userId\" : 1409219254212, \"userImage\" : 1409219254212, \"voteCount\" : 54, \"votes\" :...1409554814352, \"userId\" : 1409219253839, \"name\" : \"Kevin\", \"userImage\" : 1409219253839, \"createdAt\" : { \"$date\" : 1424035073536 } }, { \"inviteeId\" : 1418956032816, \"userId\" : 1418956032322, \"name\" : \"Dallas0908\", \"userImage\" : 1418956032322, \"createdAt\" : { \"$date\" : 1424063721989 } } ] }, \n",
    "\n",
    "{ \"ansId\" : 1424014758472, \"answerText\" : \"Yoga\", \"createdAt\" : { \"$date\" : 1424014758471 }, \"name\" : \"Yopine\", \"orderNumber\" : 2, \"userId\" : 1409219254212, \"userImage\" : 1409219254212, \"voteCount\" : 42, \"votes\" : \n",
    "\n",
    "{\"ansId\" : 1424014756823, \"answerText\" : \"Running\", \"createdAt\" : { \"$date\" : 1424014758471 }, \"name\" : \"Yopine\", \"orderNumber\" : 3, \"userId\" : 1409219254212, \"userImage\" : 1409219254212, \"voteCount\" : 17, \"votes\" : \n",
    "\n",
    "{ \"ansId\" : 1424014758474, \"answerText\" : \"Claases\", \"createdAt\" : { \"$date\" : 1424014758471 }, \"name\" : \"Yopine\", \"orderNumber\" : 4, \"userId\" : 1409219254212, \"userImage\" : 1409219254212, \"voteCount\" : 8, \"votes\" :  1424014758475, \n",
    "\n",
    "{ \"ansId\" : 1424014398274, \"answerText\" : \"Other ->\", \"createdAt\" : { \"$date\" : 1424014758471 }, \"name\" : \"Yopine\", \"orderNumber\" : 5, \"userId\" : 1409219254212, \"userImage\" : 1409219254212, \"voteCount\" : 2, \"votes\" :  } ] } ] ] } ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two places from which to draw the the data that might contain the natural categories:\n",
    "1.  pollQuestion is nice and easy...it's just a string of natural language\n",
    "    in the example the string 'Fitness: What's your jam?' - we want 'Fitness'\n",
    "2.  pollAnswer requires some crafty parsing as the relevant data is buried in each record in the field \"answerText\"\n",
    "    in the example dictionary we want 'Weights', 'Yoga', 'Running', 'Classes' and 'Other ->'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We might also like (perhaps a future endeavor) to add weight to \"answerText\" by applying its corresponding \"voteCount\" integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first step is to create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe3 in position 4426: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4cf79dd2f658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'poll3.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create df 'data' using pandas read csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/IPython/core/displayhook.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcull_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/displayhook.pyc\u001b[0m in \u001b[0;36mfinish_displayhook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/session.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/session.pyc\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# content is already packed, as in a relayed message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/session.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/site-packages/zmq/utils/jsonapi.pyc\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'separators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         sort_keys=sort_keys, **kw).encode(obj)\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/garywmendel/anaconda/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe3 in position 4426: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# Import Yopine data\n",
    "data = pd.read_csv('poll3.csv') # create df 'data' using pandas read csv\n",
    "d = data\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brennan reviewed and organized the DF into groups (categories) - poll3_grouped.csv \n",
    "https://www.dropbox.com/s/kv7mjndpxa291x3/poll3_grouped.csv?dl=0\n",
    "\n",
    "He added the 'a _groups' column to it and organized it into animals, anyone, books, brands, business, celebrity, class, coffee, contest, dancing, donate, drinks, fashion, favorites, food, games, gear, health, hobbies, holidays, home, jobs, joke, love, meetup, mood, movies, music, news, outdoors, party, places, plans, politics, religion, rides, school, shopping, smoke, social, sports, startups, tech, test, travel, tv, weather;\n",
    "+ 1657 rows un-categorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I need to get the code that performed the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA for Natural Language Processing - I want to create a repeatable model that, given any pollAnswer or pollQuestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lda\n",
    "import numpy as np # not able to import LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sentences = [\"my name is sinan\", \"Im gary\", \"This is gary and sinan\"]\n",
    "# Instantiate a count vectorizer with two additional parameters\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=[1,3]) \n",
    "sentences_train = vect.fit_transform(sentences)\n",
    "\n",
    "# Instantiate an LDA model\n",
    "model = lda.LDA(n_topics=10, n_iter=500)\n",
    "model.fit(sentences_train) # Fit the model \n",
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vect.get_feature_names())[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ', '.join(topic_words)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next (future) process to be applied is k-means and TDIFvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import TFIDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# pollAnswer field is a JSON object\n",
    "# read the Sony pollAnswer into an object called 'sony'\n",
    "import json\n",
    "# code to look at one single record\n",
    "# sony = json.loads(data.pollAnswer[3881])\n",
    "# Need to extract sentence(s) list from data\n",
    "\n",
    "# iterate to create 2 lists, poll and answer then write them to questions and answers:\n",
    "# data.head()\n",
    "#for i in range(0,len(data)):\n",
    "#    poll = json.loads(data.pollAnswer[i])\n",
    "#    print data.pollQuestion[i]\n",
    "#    poll_tally = {}\n",
    "#    for answer in poll:\n",
    "#         key = answer['answerText']\n",
    "#         if 'votes' in answer.keys():\n",
    "#             value = len(answer['votes'])\n",
    "#         poll_tally[key] = value\n",
    "#    print poll_tally\n",
    "# json.loads(data.pollAnswer[0])\n",
    "# questions = data.pollQuestion\n",
    "# answers = [' '.join([b['answerText'] for b in json.loads(a)]) for a in data.pollAnswer]\n",
    "#for q, a in zip(questions, answers):\n",
    "#    print q, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means _ TDIDFvectorizer - to group similar data in to sets (clustering) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentence_list=[data]  \n",
    "# Need to dump this into a new df\n",
    "\n",
    "# sentence_list=['hello how are you', \"I am doing great\", \"my name is abc\"]\n",
    "\n",
    "vectorizer=TfidfVectorizer(min_df=1, max_df=0.9, stop_words='english', decode_error='ignore')\n",
    "vectorized=vectorizer.fit_transform(answers)\n",
    "# vectorized=vectorizer.fit_transform(questions)\n",
    "\n",
    "km=KMeans(n_clusters=3, init='k-means++',n_init=10)\n",
    "km.fit(vectorized)\n",
    "print vectorized\n",
    "\n",
    "# i now need to take the tfidf scores and interpret them\n",
    "\n",
    "km.labels_\n",
    "\n",
    "# Stuck here - types i believe\n",
    "km.predict(vectorizer.fit_transform(answers))\n",
    "km.predict(vectorizer.fit_transform(questions))\n",
    "\n",
    "# Run KMeans\n",
    "est = KMeans(n_clusters=3, init='random')\n",
    "# need to remove non strings from data first\n",
    "\n",
    "est.fit(d) \n",
    "y_kmeans = est.predict(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I would like some output in the form of pollQuestion in - dataframe table & pollAnswer in -> dataframe table that i can add to my slide presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAT4-FinalProj slides - https://www.dropbox.com/s/on072oij3p4jlno/DAT4-FinalProj.pptx?dl=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
